## 👋 About Me
Hi! I'm **Oscar HO**, a Computer Science student passionate about accessibility, creative technology, and user-centric design. I enjoy working on impactful tech projects, from AI-driven accessibility tools to mobile experiences that empower users.

I have a strong foundation in full-stack development, mobile apps, and system administration. Outside of academics, I like to play the piano and experiment with how technology can improve everyday experiences.

- 🧠 **Programming:** Java, Python, Swift, C#
- 🌐 **Web Dev:** HTML, CSS, JavaScript, PHP
- 🖥️ **Dev Tools:** Figma, Git, Visual Studio Code, IntelliJ, Xcode, Android Studio
- 🐧 **Sysadmin:** Proficient in Linux commands, SQL databases, Cloudflare configuration
- 🌍 **Languages:** Fluent in English, Cantonese, and Mandarin
- ⌨️ **Typing:** 50–60 wpm (English), 30 wpm (Chinese)

---

## 🚀 Projects

### 🌀 Haptic Jam (2025 – Present)
An inclusive iOS platform that transforms music into a tactile and visual experience for the deaf and hard-of-hearing community. Users can feel rhythm and melody through Core Haptics and visual synchronization.

**Key Features:**
- 🎼 MIDI to vibration mapping via Core Haptics
- 📲 iPhone Taptic Engine integration for rich feedback
- 🔁 Real-time response for beat and pitch
- 👥 Social co-creation and education applications

🛠️ Built with: **Swift**, **Core Haptics**, **Taptic Engine**, **MIDIKit**  

---

### 🔊 AudioSense (2023 – 2025)
An AI-powered audio description platform designed for the visually impaired. AudioSense leverages machine learning and cloud infrastructure to streamline the end-to-end process—from video analysis to narration—making visual media more inclusive.

**Key Features:**
- 📊 AI Video Accessibility Assessment to analyze background audio and visual complexity
- 🎞️ Scene analysis with frame-level object/event recognition
- ✍️ Script generation using AI-driven summarization and context matching
- 🗣️ Multilingual narration with customizable voice settings
- 📱 Simple mobile/web interfaces with support for voice control and Siri integration

🛠️ Built with: **Python**, **OpenAI**, **React**, **FastAPI**

---

## 📊 GitHub Stats
<div align="center">
  <img src="https://github-profile-summary-cards.vercel.app/api/cards/profile-details?username=Flucus&theme=dark" />
  <br><br>
  <img src="https://github-readme-stats.vercel.app/api?username=Flucus&count_private=true&show_icons=true&theme=dark" />
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=Flucus&layout=compact&langs_count=12&theme=dark" />
</div>

---

## 🔗 Connect With Me
- [X (Twitter)](https://x.com/Flucus0929/)
- [Instagram](https://www.instagram.com/flucus.idv.hk/)
- [Threads](https://www.threads.net/@flucus.idv.hk/)
- [Facebook](https://www.facebook.com/flucus0929)
- [GitHub](https://github.com/Flucus)
- [YouTube](https://www.youtube.com/channel/UCDPqwAfdIp-YyGrNL7T4n6g)
